
![Foto do Projeto GembaGuard](https://github.com/eumoas/GembaGuard/blob/main/docs/images/residencia.jpeg?raw=true)

#  GEMBAGUARD - SISTEMA INTELIGENTE DE MANUTEN√á√ÉO PREDITIVA


## üìã Entendimento do neg√≥cio

A manuten√ß√£o preditiva permite a detec√ß√£o de problemas antes de ocorrerem
falhas atrav√©s do monitoramento de desempenho e condi√ß√µes de m√°quinas e
equipamentos em tempo real. Isso significa evitar paradas imprevistas que causam
perda de produ√ß√£o e gastos adicionais com manuten√ß√£o corretiva, ajudando a
prolongar a vida √∫til dos ativos. 

## üìã Descri√ß√£o do Projeto


Este projeto implementa um sistema inteligente fazendo uso de t√©cnicas de machine learning. Foi desenvolvido como parte do Bootcamp de Ci√™ncia de Dados e Intelig√™ncia Artificial do UniSenai. 



![Foto do Projeto GembaGuard](https://github.com/eumoas/GembaGuard/blob/main/docs/images//manuten%C3%A7%C3%A3o.gif?raw=true)



.

## üéØ Objetivos

- Desenvolver um sistema de classifica√ß√£o multiclasse para detectar 7 tipos de defeitos
- Implementar modelos de Machine Learning com alta precis√£o e recall
- Criar uma aplica√ß√£o web interativa para predi√ß√£o de defeitos
- Seguir a metodologia CRISP-DM para desenvolvimento estruturado

## üîß Tecnologias Utilizadas

- **Python 3.11**
- **Pandas** - Manipula√ß√£o de dados
- **Scikit-learn** - Algoritmos de Machine Learning
- **XGBoost** - Gradient Boosting
- **Imbalanced-learn** - SMOTE para balanceamento de classes
- **Matplotlib/Seaborn** - Visualiza√ß√£o de dados
- **Streamlit** - Interface web interativa

## üìä Dataset

O dataset cont√©m 35.260 amostras com 14 caracter√≠sticas extra√≠das de informa√ß√µes coletadas a partir de dispositivos IoT sensorizando atributos
b√°sicos de cada m√°quina.

- **Caracter√≠sticas geom√©tricas**: coordenadas, √°rea, per√≠metro
- **Caracter√≠sticas de luminosidade**: valores m√≠nimos, m√°ximos e soma
- **√çndices calculados**: orienta√ß√£o, bordas, varia√ß√£o
- **Par√¢metros do processo**: temperatura, tipo de a√ßo, espessura

### Classes de Defeitos
- **falha_3**: 649 amostras
- **falha_6**: 806 amostras  
- **sem_falha**: 1.935 amostras


### Par√¢metros do Processo

- **id_produto**: Identificador √∫nico do produto (combina√ß√£o da vari√°vel tipo e um n√∫mero)

- **tipo**: Tipo de produto/m√°quina (L / M / H)

- **temperatura_ar**: Temperatura do ar no ambiente (K)

- **temperatura_processo**: Temperatura do processo (K)

- **umidade_relativa**: Umidade relativa do ar (%)

- **velocidade_rotacional**: Velocidade rotacional da m√°quina em rota√ß√µes por minuto (RPM)

- **torque**: Torque da m√°quina em Nm

- **desgaste_da_ferramenta**: Dura√ß√£o do uso da ferramenta em minutos]


 ### Identifica√ß√£o

- **id**: Identificador das amostras do banco

### Classes de Defeitos

- **falha_maquina**: Indica se houve falha na m√°quina (1) ou n√£o (0)

- **FDF**: Falha por desgaste da ferramenta (1) ou n√£o (0)

- **FDC**: Falha por dissipa√ß√£o de calor (1) ou n√£o (0)

- **FP**: Falha por pot√™ncia (1) ou n√£o (0)

- **FTE**: Falha por tens√£o excessiva (1) ou n√£o (0)

- **FA**: Falha aleat√≥ria (1) ou n√£o (0)

## üöÄ Metodologia (CRISP-DM)

### 1. Compreens√£o do Neg√≥cio
- An√°lise do problema de controle de qualidade na ind√∫stria sider√∫rgica
- Defini√ß√£o de crit√©rios de sucesso t√©cnicos e de neg√≥cio

### 2. Compreens√£o dos Dados
- An√°lise explorat√≥ria do dataset
- Identifica√ß√£o de valores ausentes e outliers
- An√°lise da distribui√ß√£o das classes

### 3. Prepara√ß√£o dos Dados
- Cria√ß√£o da coluna `falha_principal` para problema multiclasse
- Tratamento de valores ausentes com imputa√ß√£o pela mediana
- Padroniza√ß√£o das caracter√≠sticas num√©ricas
- Aplica√ß√£o de SMOTE para balanceamento de classes

### 4. Modelagem
Tr√™s algoritmos foram implementados e comparados:

#### Logistic Regression
- Accuracy: 73.01%
- Precision (Macro): 75.19%
- Recall (Macro): 77.87%
- F1-Score (Macro): 75.35%

#### Random Forest
- Accuracy: 78.47%
- Precision (Macro): 78.29%
- Recall (Macro): 78.01%
- F1-Score (Macro): 78.15%

#### XGBoost ‚≠ê **Melhor Modelo**
- Accuracy: 79.35%
- Precision (Macro): 79.10%
- Recall (Macro): 79.11%
- F1-Score (Macro): 79.10%

### 5. Avalia√ß√£o
- Valida√ß√£o cruzada com 5 folds
- Foco em m√©tricas Precision e Recall conforme solicitado
- XGBoost apresentou melhor desempenho geral

## üìÅ Estrutura do Projeto

```
‚îú‚îÄ‚îÄ data_preparation.py          # Script de prepara√ß√£o dos dados
‚îú‚îÄ‚îÄ model_training.py           # Treinamento dos modelos ML
‚îú‚îÄ‚îÄ data_visualization.py       # Gera√ß√£o de visualiza√ß√µes
‚îú‚îÄ‚îÄ streamlit_app.py           # Aplica√ß√£o web interativa
‚îú‚îÄ‚îÄ bootcamp_train.csv         # Dataset original
‚îú‚îÄ‚îÄ bootcamp_train_prepared.csv # Dataset processado
‚îú‚îÄ‚îÄ *.pkl                      # Modelos treinados salvos
‚îú‚îÄ‚îÄ *.png                      # Visualiza√ß√µes geradas
‚îî‚îÄ‚îÄ README.md                  # Este arquivo
```

## üñ•Ô∏è Como Executar

### 1. Prepara√ß√£o dos Dados
```bash
python data_preparation.py
```

### 2. Treinamento dos Modelos
```bash
python model_training.py
```

### 3. Gera√ß√£o de Visualiza√ß√µes
```bash
python data_visualization.py
```

### 4. Executar Aplica√ß√£o Streamlit
```bash
streamlit run streamlit_app.py
```

## üìà Resultados e Insights

### Principais Descobertas
1. **Desbalanceamento de Classes**: O dataset apresenta desbalanceamento significativo, com 57% das amostras sendo "sem_falha"
2. **Efic√°cia do SMOTE**: A aplica√ß√£o de SMOTE melhorou significativamente o desempenho dos modelos
3. **Superioridade do XGBoost**: O modelo XGBoost apresentou melhor desempenho em todas as m√©tricas

### Visualiza√ß√µes Geradas
- Boxplots para an√°lise de distribui√ß√£o das caracter√≠sticas
- Histogramas para an√°lise de frequ√™ncia
- Gr√°fico de contagem das classes de defeitos

## üåê Aplica√ß√£o Web

A aplica√ß√£o Streamlit oferece tr√™s funcionalidades principais:

1. **An√°lise Explorat√≥ria**: Visualiza√ß√£o interativa dos dados e estat√≠sticas
2. **Predi√ß√£o de Defeitos**: Interface para inserir caracter√≠sticas e obter predi√ß√µes
3. **M√©tricas dos Modelos**: Compara√ß√£o visual do desempenho dos modelos

## üîÆ Pr√≥ximos Passos

1. **Coleta de Mais Dados**: Aumentar o dataset para melhorar a generaliza√ß√£o
2. **Feature Engineering**: Criar novas caracter√≠sticas a partir das existentes
3. **Ensemble Methods**: Combinar m√∫ltiplos modelos para melhor performance
4. **Deploy em Produ√ß√£o**: Implementar o sistema em ambiente produtivo
5. **Monitoramento**: Criar sistema de monitoramento da performance em produ√ß√£o

## üë• Autor

**Miriam O. de Aguiar Sobral**
- Bootcamp de Ci√™ncia de Dados e Intelig√™ncia Artificial - SENAI
- Data: Agosto/2025

## üìÑ Licen√ßa

Este projeto foi desenvolvido para fins educacionais como parte do Bootcamp SENAI.

