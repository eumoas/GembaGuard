
![Foto do Projeto GembaGuard](https://github.com/eumoas/GembaGuard/blob/main/docs/images/residencia.jpeg?raw=true)

#  Gembaguard - Sistema Inteligente de PrevisÃ£o de Falhas em MÃ¡quinas



## ğŸš€ Como Executar

...

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este projeto implementa um sistema inteligente de controle de qualidade para chapas de aÃ§o inoxidÃ¡vel, desenvolvido como parte do Bootcamp de CiÃªncia de Dados e InteligÃªncia Artificial do SENAI. 



![Foto do Projeto GembaGuard](https://github.com/eumoas/GembaGuard/blob/main/docs/images//manuten%C3%A7%C3%A3o.gif?raw=true)





O sistema utiliza tÃ©cnicas de Machine Learning para detectar e classificar automaticamente defeitos em chapas de aÃ§o com base em caracterÃ­sticas extraÃ­das de imagens de superfÃ­cie.

## ğŸ¯ Objetivos

- Desenvolver um sistema de classificaÃ§Ã£o multiclasse para detectar 7 tipos de defeitos
- Implementar modelos de Machine Learning com alta precisÃ£o e recall
- Criar uma aplicaÃ§Ã£o web interativa para prediÃ§Ã£o de defeitos
- Seguir a metodologia CRISP-DM para desenvolvimento estruturado

## ğŸ”§ Tecnologias Utilizadas

- **Python 3.11**
- **Pandas** - ManipulaÃ§Ã£o de dados
- **Scikit-learn** - Algoritmos de Machine Learning
- **XGBoost** - Gradient Boosting
- **Imbalanced-learn** - SMOTE para balanceamento de classes
- **Matplotlib/Seaborn** - VisualizaÃ§Ã£o de dados
- **Streamlit** - Interface web interativa

## ğŸ“Š Dataset

O dataset contÃ©m 35.260 amostras com 14 caracterÃ­sticas extraÃ­das de informaÃ§Ãµes coletadas a partir de dispositivos IoT sensorizando atributos
bÃ¡sicos de cada mÃ¡quina.

- **CaracterÃ­sticas geomÃ©tricas**: coordenadas, Ã¡rea, perÃ­metro
- **CaracterÃ­sticas de luminosidade**: valores mÃ­nimos, mÃ¡ximos e soma
- **Ãndices calculados**: orientaÃ§Ã£o, bordas, variaÃ§Ã£o
- **ParÃ¢metros do processo**: temperatura, tipo de aÃ§o, espessura

### Classes de Defeitos
- **falha_3**: 649 amostras
- **falha_6**: 806 amostras  
- **sem_falha**: 1.935 amostras


### ParÃ¢metros do Processo

- **id_produto**: Identificador Ãºnico do produto (combinaÃ§Ã£o da variÃ¡vel tipo e um nÃºmero)

- **tipo**: Tipo de produto/mÃ¡quina (L / M / H)

- **temperatura_ar**: Temperatura do ar no ambiente (K)

- **temperatura_processo**: Temperatura do processo (K)

- **umidade_relativa**: Umidade relativa do ar (%)

- **velocidade_rotacional**: Velocidade rotacional da mÃ¡quina em rotaÃ§Ãµes por minuto (RPM)

- **torque**: Torque da mÃ¡quina em Nm

- **desgaste_da_ferramenta**: DuraÃ§Ã£o do uso da ferramenta em minutos]


 ### IdentificaÃ§Ã£o

- **id**: Identificador das amostras do banco

### Classes de Defeitos

- **falha_maquina**: Indica se houve falha na mÃ¡quina (1) ou nÃ£o (0)

- **FDF**: Falha por desgaste da ferramenta (1) ou nÃ£o (0)

- **FDC**: Falha por dissipaÃ§Ã£o de calor (1) ou nÃ£o (0)

- **FP**: Falha por potÃªncia (1) ou nÃ£o (0)

- **FTE**: Falha por tensÃ£o excessiva (1) ou nÃ£o (0)

- **FA**: Falha aleatÃ³ria (1) ou nÃ£o (0)

## ğŸš€ Metodologia (CRISP-DM)

### 1. CompreensÃ£o do NegÃ³cio
- AnÃ¡lise do problema de controle de qualidade na indÃºstria siderÃºrgica
- DefiniÃ§Ã£o de critÃ©rios de sucesso tÃ©cnicos e de negÃ³cio

### 2. CompreensÃ£o dos Dados
- AnÃ¡lise exploratÃ³ria do dataset
- IdentificaÃ§Ã£o de valores ausentes e outliers
- AnÃ¡lise da distribuiÃ§Ã£o das classes

### 3. PreparaÃ§Ã£o dos Dados
- CriaÃ§Ã£o da coluna `falha_principal` para problema multiclasse
- Tratamento de valores ausentes com imputaÃ§Ã£o pela mediana
- PadronizaÃ§Ã£o das caracterÃ­sticas numÃ©ricas
- AplicaÃ§Ã£o de SMOTE para balanceamento de classes

### 4. Modelagem
TrÃªs algoritmos foram implementados e comparados:

#### Logistic Regression
- Accuracy: 73.01%
- Precision (Macro): 75.19%
- Recall (Macro): 77.87%
- F1-Score (Macro): 75.35%

#### Random Forest
- Accuracy: 78.47%
- Precision (Macro): 78.29%
- Recall (Macro): 78.01%
- F1-Score (Macro): 78.15%

#### XGBoost â­ **Melhor Modelo**
- Accuracy: 79.35%
- Precision (Macro): 79.10%
- Recall (Macro): 79.11%
- F1-Score (Macro): 79.10%

### 5. AvaliaÃ§Ã£o
- ValidaÃ§Ã£o cruzada com 5 folds
- Foco em mÃ©tricas Precision e Recall conforme solicitado
- XGBoost apresentou melhor desempenho geral

## ğŸ“ Estrutura do Projeto

```
â”œâ”€â”€ data_preparation.py          # Script de preparaÃ§Ã£o dos dados
â”œâ”€â”€ model_training.py           # Treinamento dos modelos ML
â”œâ”€â”€ data_visualization.py       # GeraÃ§Ã£o de visualizaÃ§Ãµes
â”œâ”€â”€ streamlit_app.py           # AplicaÃ§Ã£o web interativa
â”œâ”€â”€ bootcamp_train.csv         # Dataset original
â”œâ”€â”€ bootcamp_train_prepared.csv # Dataset processado
â”œâ”€â”€ *.pkl                      # Modelos treinados salvos
â”œâ”€â”€ *.png                      # VisualizaÃ§Ãµes geradas
â””â”€â”€ README.md                  # Este arquivo
```

## ğŸ–¥ï¸ Como Executar

### 1. PreparaÃ§Ã£o dos Dados
```bash
python data_preparation.py
```

### 2. Treinamento dos Modelos
```bash
python model_training.py
```

### 3. GeraÃ§Ã£o de VisualizaÃ§Ãµes
```bash
python data_visualization.py
```

### 4. Executar AplicaÃ§Ã£o Streamlit
```bash
streamlit run streamlit_app.py
```

## ğŸ“ˆ Resultados e Insights

### Principais Descobertas
1. **Desbalanceamento de Classes**: O dataset apresenta desbalanceamento significativo, com 57% das amostras sendo "sem_falha"
2. **EficÃ¡cia do SMOTE**: A aplicaÃ§Ã£o de SMOTE melhorou significativamente o desempenho dos modelos
3. **Superioridade do XGBoost**: O modelo XGBoost apresentou melhor desempenho em todas as mÃ©tricas

### VisualizaÃ§Ãµes Geradas
- Boxplots para anÃ¡lise de distribuiÃ§Ã£o das caracterÃ­sticas
- Histogramas para anÃ¡lise de frequÃªncia
- GrÃ¡fico de contagem das classes de defeitos

## ğŸŒ AplicaÃ§Ã£o Web

A aplicaÃ§Ã£o Streamlit oferece trÃªs funcionalidades principais:

1. **AnÃ¡lise ExploratÃ³ria**: VisualizaÃ§Ã£o interativa dos dados e estatÃ­sticas
2. **PrediÃ§Ã£o de Defeitos**: Interface para inserir caracterÃ­sticas e obter prediÃ§Ãµes
3. **MÃ©tricas dos Modelos**: ComparaÃ§Ã£o visual do desempenho dos modelos

## ğŸ”® PrÃ³ximos Passos

1. **Coleta de Mais Dados**: Aumentar o dataset para melhorar a generalizaÃ§Ã£o
2. **Feature Engineering**: Criar novas caracterÃ­sticas a partir das existentes
3. **Ensemble Methods**: Combinar mÃºltiplos modelos para melhor performance
4. **Deploy em ProduÃ§Ã£o**: Implementar o sistema em ambiente produtivo
5. **Monitoramento**: Criar sistema de monitoramento da performance em produÃ§Ã£o

## ğŸ‘¥ Autor

**Miriam O. de Aguiar Sobral**
- Bootcamp de CiÃªncia de Dados e InteligÃªncia Artificial - SENAI
- Data: Agosto/2025

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido para fins educacionais como parte do Bootcamp SENAI.

